{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BiGRU All Feature"
      ],
      "metadata": {
        "id": "l3TlxXigbRKX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alEiUMHYbITG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Bidirectional, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/phishing+websites/phishingDataset.xlsx'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel(data_path)\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\nShape of the dataset:\", df.shape)\n",
        "\n",
        "# Menghapus baris duplikat\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(\"Shape after removing duplicates:\", df.shape)\n",
        "\n",
        "# Fungsi untuk membersihkan data byte string\n",
        "def clean_byte_string(s):\n",
        "    return s.decode('utf-8') if isinstance(s, bytes) else s\n",
        "\n",
        "# Menerapkan fungsi ke setiap elemen dalam DataFrame\n",
        "df = df.applymap(clean_byte_string)\n",
        "\n",
        "# Mengonversi kolom yang seharusnya numerik\n",
        "for col in df.columns:\n",
        "    df[col] = pd.to_numeric(df[col].str.strip(\"b'\"), errors='coerce')\n",
        "\n",
        "# Memeriksa ulang missing values setelah konversi\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values in each column after conversion:\\n\", missing_values)\n",
        "\n",
        "# Menghapus baris dengan missing values\n",
        "df.dropna(inplace=True)\n",
        "print(\"Shape after removing missing values:\", df.shape)\n",
        "\n",
        "# Normalisasi fitur numerik\n",
        "scaler = MinMaxScaler()\n",
        "df[df.columns] = scaler.fit_transform(df)\n",
        "print(\"First 5 rows after normalization:\\n\", df.head())\n",
        "\n",
        "# Memisahkan fitur dan label\n",
        "X = df.drop('Result', axis=1)\n",
        "y = df['Result']\n",
        "\n",
        "# Ubah label menjadi kategori\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Memvisualisasikan jumlah masing-masing kelas sebagai diagram pie\n",
        "class_counts = pd.DataFrame(y).idxmax(axis=1).value_counts()\n",
        "class_labels = class_counts.index\n",
        "class_sizes = class_counts.values\n",
        "class_percentages = (class_sizes / class_sizes.sum()) * 100\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.pie(class_sizes, labels=[f'{label}: {size} ({percentage:.2f}%)' for label, size, percentage in zip(class_labels, class_sizes, class_percentages)],\n",
        "        autopct='%1.1f%%', startangle=140, colors=sns.color_palette(\"pastel\"))\n",
        "plt.title('Distribution of Classes')\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "# Inisialisasi model BiGRU\n",
        "def create_model(input_shape, output_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(GRU(64, return_sequences=True), input_shape=input_shape))\n",
        "    model.add(Bidirectional(GRU(64)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(output_shape, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "auc_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Reshape data untuk sesuai dengan input GRU\n",
        "    X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    # Buat dan latih model\n",
        "    model = create_model((X_train.shape[1], 1), y_train.shape[1])\n",
        "    history = model.fit(X_train_reshaped, y_train, epochs=25, batch_size=32, validation_split=0.2, verbose=2)\n",
        "\n",
        "    # Memprediksi data testing\n",
        "    y_pred = model.predict(X_test_reshaped)\n",
        "    y_pred_classes = y_pred.argmax(axis=1)\n",
        "    y_test_classes = y_test.argmax(axis=1)\n",
        "\n",
        "    # Evaluasi model\n",
        "    accuracy_scores.append(accuracy_score(y_test_classes, y_pred_classes))\n",
        "    precision_scores.append(precision_score(y_test_classes, y_pred_classes))\n",
        "    recall_scores.append(recall_score(y_test_classes, y_pred_classes))\n",
        "    f1_scores.append(f1_score(y_test_classes, y_pred_classes))\n",
        "    auc_scores.append(roc_auc_score(y_test_classes, y_pred_classes))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "print(f\"Mean Accuracy: {sum(accuracy_scores)/len(accuracy_scores)}\")\n",
        "print(f\"Mean Precision: {sum(precision_scores)/len(precision_scores)}\")\n",
        "print(f\"Mean Recall: {sum(recall_scores)/len(recall_scores)}\")\n",
        "print(f\"Mean F1 Score: {sum(f1_scores)/len(f1_scores)}\")\n",
        "print(f\"Mean AUC: {sum(auc_scores)/len(auc_scores)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiGRU+FSFM"
      ],
      "metadata": {
        "id": "TPY0YaexbVjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Bidirectional, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/phishing+websites/phishingDataset.xlsx'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel(data_path)\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\nShape of the dataset:\", df.shape)\n",
        "\n",
        "# Menghapus baris duplikat\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(\"Shape after removing duplicates:\", df.shape)\n",
        "\n",
        "# Fungsi untuk membersihkan data byte string\n",
        "def clean_byte_string(s):\n",
        "    return s.decode('utf-8') if isinstance(s, bytes) else s\n",
        "\n",
        "# Menerapkan fungsi ke setiap elemen dalam DataFrame\n",
        "df = df.applymap(clean_byte_string)\n",
        "\n",
        "# Mengonversi kolom yang seharusnya numerik\n",
        "for col in df.columns:\n",
        "    df[col] = pd.to_numeric(df[col].str.strip(\"b'\"), errors='coerce')\n",
        "\n",
        "# Memeriksa ulang missing values setelah konversi\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values in each column after conversion:\\n\", missing_values)\n",
        "\n",
        "# Menghapus baris dengan missing values\n",
        "df.dropna(inplace=True)\n",
        "print(\"Shape after removing missing values:\", df.shape)\n",
        "\n",
        "# Normalisasi fitur numerik\n",
        "scaler = MinMaxScaler()\n",
        "df[df.columns] = scaler.fit_transform(df)\n",
        "print(\"First 5 rows after normalization:\\n\", df.head())\n",
        "\n",
        "# Memisahkan fitur dan label\n",
        "selected_features = [14, 8, 26, 7, 6, 15, 16, 29, 1, 27, 2]\n",
        "X = df.iloc[:, selected_features]\n",
        "y = df['Result']\n",
        "\n",
        "# Ubah label menjadi kategori\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Memvisualisasikan jumlah masing-masing kelas sebagai diagram pie\n",
        "class_counts = pd.DataFrame(y).idxmax(axis=1).value_counts()\n",
        "class_labels = class_counts.index\n",
        "class_sizes = class_counts.values\n",
        "class_percentages = (class_sizes / class_sizes.sum()) * 100\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.pie(class_sizes, labels=[f'{label}: {size} ({percentage:.2f}%)' for label, size, percentage in zip(class_labels, class_sizes, class_percentages)],\n",
        "        autopct='%1.1f%%', startangle=140, colors=sns.color_palette(\"pastel\"))\n",
        "plt.title('Distribution of Classes')\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "# Inisialisasi model BiGRU\n",
        "def create_model(input_shape, output_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(GRU(64, return_sequences=True), input_shape=input_shape))\n",
        "    model.add(Bidirectional(GRU(64)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(output_shape, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "auc_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Reshape data untuk sesuai dengan input GRU\n",
        "    X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    # Buat dan latih model\n",
        "    model = create_model((X_train.shape[1], 1), y_train.shape[1])\n",
        "    history = model.fit(X_train_reshaped, y_train, epochs=25, batch_size=32, validation_split=0.2, verbose=2)\n",
        "\n",
        "    # Memprediksi data testing\n",
        "    y_pred = model.predict(X_test_reshaped)\n",
        "    y_pred_classes = y_pred.argmax(axis=1)\n",
        "    y_test_classes = y_test.argmax(axis=1)\n",
        "\n",
        "    # Evaluasi model\n",
        "    accuracy_scores.append(accuracy_score(y_test_classes, y_pred_classes))\n",
        "    precision_scores.append(precision_score(y_test_classes, y_pred_classes))\n",
        "    recall_scores.append(recall_score(y_test_classes, y_pred_classes))\n",
        "    f1_scores.append(f1_score(y_test_classes, y_pred_classes))\n",
        "    auc_scores.append(roc_auc_score(y_test_classes, y_pred_classes))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "print(f\"Mean Accuracy: {sum(accuracy_scores)/len(accuracy_scores)}\")\n",
        "print(f\"Mean Precision: {sum(precision_scores)/len(precision_scores)}\")\n",
        "print(f\"Mean Recall: {sum(recall_scores)/len(recall_scores)}\")\n",
        "print(f\"Mean F1 Score: {sum(f1_scores)/len(f1_scores)}\")\n",
        "print(f\"Mean AUC: {sum(auc_scores)/len(auc_scores)}\")\n"
      ],
      "metadata": {
        "id": "n9qctU3VbYB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiGRU+FSOR"
      ],
      "metadata": {
        "id": "8PZoOpRhbbU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Bidirectional, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/phishing+websites/phishingDataset.xlsx'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel(data_path)\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\nShape of the dataset:\", df.shape)\n",
        "\n",
        "# Menghapus baris duplikat\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(\"Shape after removing duplicates:\", df.shape)\n",
        "\n",
        "# Fungsi untuk membersihkan data byte string\n",
        "def clean_byte_string(s):\n",
        "    return s.decode('utf-8') if isinstance(s, bytes) else s\n",
        "\n",
        "# Menerapkan fungsi ke setiap elemen dalam DataFrame\n",
        "df = df.applymap(clean_byte_string)\n",
        "\n",
        "# Mengonversi kolom yang seharusnya numerik\n",
        "for col in df.columns:\n",
        "    df[col] = pd.to_numeric(df[col].str.strip(\"b'\"), errors='coerce')\n",
        "\n",
        "# Memeriksa ulang missing values setelah konversi\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values in each column after conversion:\\n\", missing_values)\n",
        "\n",
        "# Menghapus baris dengan missing values\n",
        "df.dropna(inplace=True)\n",
        "print(\"Shape after removing missing values:\", df.shape)\n",
        "\n",
        "# Normalisasi fitur numerik\n",
        "scaler = MinMaxScaler()\n",
        "df[df.columns] = scaler.fit_transform(df)\n",
        "print(\"First 5 rows after normalization:\\n\", df.head())\n",
        "\n",
        "# Memisahkan fitur dan label\n",
        "selected_features = [1, 2, 3, 4, 6, 7, 8, 9, 11, 13, 14, 15, 16, 20, 21, 24, 25, 26, 27, 28, 29, 30]\n",
        "X = df.iloc[:, selected_features]\n",
        "y = df['Result']\n",
        "\n",
        "# Ubah label menjadi kategori\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Memvisualisasikan jumlah masing-masing kelas sebagai diagram pie\n",
        "class_counts = pd.DataFrame(y).idxmax(axis=1).value_counts()\n",
        "class_labels = class_counts.index\n",
        "class_sizes = class_counts.values\n",
        "class_percentages = (class_sizes / class_sizes.sum()) * 100\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.pie(class_sizes, labels=[f'{label}: {size} ({percentage:.2f}%)' for label, size, percentage in zip(class_labels, class_sizes, class_percentages)],\n",
        "        autopct='%1.1f%%', startangle=140, colors=sns.color_palette(\"pastel\"))\n",
        "plt.title('Distribution of Classes')\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "# Inisialisasi model BiGRU\n",
        "def create_model(input_shape, output_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(GRU(64, return_sequences=True), input_shape=input_shape))\n",
        "    model.add(Bidirectional(GRU(64)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(output_shape, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "auc_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Reshape data untuk sesuai dengan input GRU\n",
        "    X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    # Buat dan latih model\n",
        "    model = create_model((X_train.shape[1], 1), y_train.shape[1])\n",
        "    history = model.fit(X_train_reshaped, y_train, epochs=25, batch_size=32, validation_split=0.2, verbose=2)\n",
        "\n",
        "    # Memprediksi data testing\n",
        "    y_pred = model.predict(X_test_reshaped)\n",
        "    y_pred_classes = y_pred.argmax(axis=1)\n",
        "    y_test_classes = y_test.argmax(axis=1)\n",
        "\n",
        "    # Evaluasi model\n",
        "    accuracy_scores.append(accuracy_score(y_test_classes, y_pred_classes))\n",
        "    precision_scores.append(precision_score(y_test_classes, y_pred_classes))\n",
        "    recall_scores.append(recall_score(y_test_classes, y_pred_classes))\n",
        "    f1_scores.append(f1_score(y_test_classes, y_pred_classes))\n",
        "    auc_scores.append(roc_auc_score(y_test_classes, y_pred_classes))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "print(f\"Mean Accuracy: {sum(accuracy_scores)/len(accuracy_scores)}\")\n",
        "print(f\"Mean Precision: {sum(precision_scores)/len(precision_scores)}\")\n",
        "print(f\"Mean Recall: {sum(recall_scores)/len(recall_scores)}\")\n",
        "print(f\"Mean F1 Score: {sum(f1_scores)/len(f1_scores)}\")\n",
        "print(f\"Mean AUC: {sum(auc_scores)/len(auc_scores)}\")\n"
      ],
      "metadata": {
        "id": "w43PF8RjbdQc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}